<source>
  @type tcp
  port 5170
  bind 0.0.0.0
  format json
  tag systemd
</source>

<filter systemd.**>
  type record_transformer
  renew_record true
  <record>
    hostname ${_HOSTNAME}
    unit ${_SYSTEMD_UNIT}
    bin ${_EXE}
    log ${MESSAGE}
  </record>
</filter>

# Do not directly collect fluentd's own logs to avoid infinite loops.
<match fluent.**>
  type null
</match>

<source>
  type tail
  path /var/lib/docker/containers/*/*-json.log
  pos_file /tmp/k8s-containers.log.pos
  tag docker.*
  format json
  time_key time
  time_format %Y-%m-%dT%H:%M:%S.%N%z
  read_from_head true
</source>

<filter kubernetes.**>
  type kubernetes_metadata
</filter>

<filter docker.var.lib.docker.containers.**>
  type record_transformer
  #remove_keys log
  renew_record false
  enable_ruby false
  <record>
    container_id ${tag_parts[5]}
  </record>
</filter>

<match **>
  type elasticsearch
  include_tag_key true
  host elasticsearch.default.svc.cluster.local
  port 9200
  logstash_format true
  # Set the chunk limit the same as for fluentd-gcp.
  buffer_chunk_limit 2M
  # Cap buffer memory usage to 2MiB/chunk * 32 chunks = 64 MiB
  buffer_queue_limit 32
  flush_interval 5s
  # Never wait longer than 5 minutes between retries.
  max_retry_wait 30
  # Disable the limit on the number of retries (retry forever).
  disable_retry_limit
  num_threads 1
  reload_connections false
</match>

#<match **>
#  type file
#  path /tmp/fluentd/debug
#  append true
#  time_slice_format %Y%m%d
#  time_format %Y%m%dT%H%M%S%z
#  flush_interval 5s
#</match>
